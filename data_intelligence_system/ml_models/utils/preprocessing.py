import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import (
    StandardScaler,
    MinMaxScaler,
    RobustScaler,
    LabelEncoder
)
import logging

from data_intelligence_system.utils.preprocessing import fill_missing_values  # âœ… Ù…Ø­Ø¯Ø«

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataPreprocessor:
    def __init__(self, scaler_type="standard", test_size=0.2, random_state=42):
        self.scaler_type = scaler_type
        self.test_size = test_size
        self.random_state = random_state
        self.scaler = None
        self.label_encoders = {}

    def fit_scaler(self, X):
        if self.scaler_type == "standard":
            self.scaler = StandardScaler()
        elif self.scaler_type == "minmax":
            self.scaler = MinMaxScaler()
        elif self.scaler_type == "robust":
            self.scaler = RobustScaler()
        else:
            logger.warning(f"Ù†ÙˆØ¹ Ø§Ù„Ø³ÙƒÙŠÙ„Ø± '{self.scaler_type}' ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ. Ø³ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø³ÙƒÙŠÙ„ÙŠÙ†Ø¬.")
            self.scaler = None

        if self.scaler:
            self.scaler.fit(X)
        return self

    def transform_scaler(self, X):
        if self.scaler:
            try:
                return self.scaler.transform(X)
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„Ø³ÙƒÙŠÙ„Ø±: {e}")
                raise
        return X

    def inverse_transform_scaler(self, X):
        if self.scaler:
            try:
                return self.scaler.inverse_transform(X)
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø¹ÙƒØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨Ø§Ù„Ø³ÙƒÙŠÙ„Ø±: {e}")
                raise
        return X

    def fit_transform_scaler(self, X):
        self.fit_scaler(X)
        return self.transform_scaler(X)

    def detect_categorical_columns(self, df):
        return df.select_dtypes(include=["object", "category"]).columns.tolist()

    def encode_labels(self, df, categorical_cols):
        for col in categorical_cols:
            if col not in self.label_encoders:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
                self.label_encoders[col] = le
            else:
                le = self.label_encoders[col]
                try:
                    df[col] = le.transform(df[col].astype(str))
                except ValueError as e:
                    logger.error(f"Ù‚ÙŠÙ… Ø¬Ø¯ÙŠØ¯Ø© ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ© ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ '{col}': {e}")
                    raise
        return df

    def decode_labels(self, df, categorical_cols):
        for col in categorical_cols:
            if col in self.label_encoders:
                le = self.label_encoders[col]
                try:
                    df[col] = le.inverse_transform(df[col])
                except Exception as e:
                    logger.error(f"Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ÙÙƒ Ø§Ù„ØªØ±Ù…ÙŠØ² ÙÙŠ Ø§Ù„Ø¹Ù…ÙˆØ¯ '{col}': {e}")
                    raise
        return df

    def split(self, X, y=None):
        try:
            if y is not None and len(np.unique(y)) > 1:
                return train_test_split(
                    X, y,
                    test_size=self.test_size,
                    random_state=self.random_state,
                    stratify=y
                )
            elif y is not None:
                logger.warning("ğŸš¨ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙØ¦Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·. Ø³ÙŠØªÙ… Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¨Ø¯ÙˆÙ† stratify.")
                return train_test_split(
                    X, y,
                    test_size=self.test_size,
                    random_state=self.random_state
                )
            else:
                return train_test_split(
                    X,
                    test_size=self.test_size,
                    random_state=self.random_state
                )
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            raise

    def preprocess(self, df, target_col=None, categorical_cols=None, scale=True):
        df = df.copy()

        # âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©
        df = fill_missing_values(df)

        initial_shape = df.shape
        df.dropna(axis=0, how='any', inplace=True)
        dropped_rows = initial_shape[0] - df.shape[0]
        if dropped_rows > 0:
            logger.info(f"ØªÙ… Ø­Ø°Ù {dropped_rows} ØµÙÙˆÙ Ø¨Ø³Ø¨Ø¨ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ© Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.")

        if categorical_cols is None:
            categorical_cols = self.detect_categorical_columns(df)

        if categorical_cols:
            df = self.encode_labels(df, categorical_cols)

        if target_col and target_col in df.columns:
            X = df.drop(columns=[target_col])
            y = df[target_col].values
        else:
            X = df
            y = None

        categorical_cols = categorical_cols or []
        numeric_cols = [col for col in X.select_dtypes(include=[np.number]).columns if col not in categorical_cols]

        if scale and numeric_cols:
            self.fit_scaler(X[numeric_cols])
            X_scaled = self.transform_scaler(X[numeric_cols])
            X.loc[:, numeric_cols] = X_scaled

        if y is not None:
            return self.split(X, y)
        else:
            return self.split(X)


# Ø§Ø®ØªØ¨Ø§Ø± ØªØ¬Ø±ÙŠØ¨ÙŠ
if __name__ == "__main__":
    data = {
        "feature1": [10, 20, 30, 40, 50, None],
        "feature2": [0.1, 0.2, 0.3, None, 0.5, 0.6],
        "category": ["A", "B", "A", "B", "C", "C"],
        "target": [1, 0, 1, 0, 1, 0]
    }
    df = pd.DataFrame(data)

    preprocessor = DataPreprocessor(scaler_type="standard", test_size=0.4)
    X_train, X_test, y_train, y_test = preprocessor.preprocess(
        df,
        target_col="target",
        categorical_cols=None,  # Ø§ÙƒØªØ´Ø§Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ
        scale=True
    )

    print("X_train:\n", X_train)
    print("y_train:\n", y_train)
