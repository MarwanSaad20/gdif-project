import logging
import joblib
from pathlib import Path
from typing import Optional, List

from xgboost import XGBClassifier

# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…Ù† Ø¬Ø°Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
from data_intelligence_system.config.paths_config import ML_MODELS_DIR
from data_intelligence_system.ml_models.base_model import BaseModel
from data_intelligence_system.ml_models.utils.model_evaluation import ClassificationMetrics
from data_intelligence_system.ml_models.utils.preprocessing import DataPreprocessor
from data_intelligence_system.utils.preprocessing import fill_missing_values
from data_intelligence_system.utils.feature_utils import generate_derived_features
from data_intelligence_system.utils.timer import Timer

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class XGBoostClassifierModel(BaseModel):
    """
    Ù†Ù…ÙˆØ°Ø¬ XGBoost Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… scikit-learn.
    """

    def __init__(
        self,
        model_params: Optional[dict] = None,
        scaler_type: str = "standard"
    ):
        super().__init__(model_name="xgboost_classifier", model_dir=ML_MODELS_DIR)
        self.model_params = model_params if model_params else {}
        self.model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', **self.model_params)
        self.preprocessor = DataPreprocessor(scaler_type=scaler_type)
        self.is_fitted = False

    def _prepare_features(self, X, categorical_cols: Optional[List[str]] = None):
        """
        ØªÙ†Ø¸ÙŠÙ ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù„Ù„ØªÙ†Ø¨Ø¤ Ø£Ùˆ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
        """
        if X is None or X.empty:
            raise ValueError("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙØ§Ø±ØºØ© Ø£Ùˆ None.")
        X = fill_missing_values(X)
        X = generate_derived_features(X)
        if categorical_cols:
            X = self.preprocessor.encode_labels(X.copy(), categorical_cols)
        return self.preprocessor.transform_scaler(X)

    @Timer("ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost")
    def fit(self, X, y, categorical_cols: Optional[List[str]] = None):
        """
        ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ØªÙ‚ÙŠÙŠÙ….

        Raises
        ------
        ValueError: Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ØªÙ†Ø§Ø³Ù‚Ø© Ø£Ùˆ ÙØ§Ø±ØºØ©.
        """
        if X is None or y is None:
            raise ValueError("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£Ùˆ Ø§Ù„Ù‡Ø¯Ù ÙØ§Ø±ØºØ©.")
        if len(X) != len(y):
            raise ValueError("âŒ Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª ÙÙŠ X Ùˆ y ØºÙŠØ± Ù…ØªØ·Ø§Ø¨Ù‚.")

        X_processed = self._prepare_features(X, categorical_cols)

        if categorical_cols:
            df = X_processed.assign(target=y)
            X_train, X_test, y_train, y_test = self.preprocessor.preprocess(
                df, target_col="target", categorical_cols=categorical_cols, scale=True
            )
        else:
            X_train, X_test, y_train, y_test = self.preprocessor.split(X_processed, y)

        try:
            self.model.fit(X_train, y_train)
            self.is_fitted = True
            logger.info("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost.")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            raise

        y_pred = self.model.predict(X_test)

        avg_method = "binary" if len(set(y)) == 2 else "weighted"

        return ClassificationMetrics.all_metrics(y_test, y_pred, average=avg_method)

    def predict(self, X, categorical_cols: Optional[List[str]] = None):
        """
        Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ¦Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨.
        """
        self._check_is_fitted()
        X_prepared = self._prepare_features(X, categorical_cols)
        return self.model.predict(X_prepared)

    def predict_proba(self, X, categorical_cols: Optional[List[str]] = None):
        """
        Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„ÙØ¦Ø§Øª.
        """
        self._check_is_fitted()
        X_prepared = self._prepare_features(X, categorical_cols)
        return self.model.predict_proba(X_prepared)

    def evaluate(self, X, y, categorical_cols: Optional[List[str]] = None):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.
        """
        self._check_is_fitted()
        if X is None or y is None:
            raise ValueError("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø£Ùˆ Ø§Ù„Ù‡Ø¯Ù ÙØ§Ø±ØºØ©.")

        X_prepared = self._prepare_features(X, categorical_cols)
        y_pred = self.model.predict(X_prepared)

        avg_method = "binary" if len(set(y)) == 2 else "weighted"

        return ClassificationMetrics.all_metrics(y, y_pred, average=avg_method)

    def save(self):
        """
        Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.
        """
        if self.model is None:
            raise ValueError("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ø­ÙØ¸Ù‡.")
        try:
            self.model_path.parent.mkdir(parents=True, exist_ok=True)
            joblib.dump({
                "model": self.model,
                "preprocessor": self.preprocessor,
                "is_fitted": self.is_fitted
            }, self.model_path)
            logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {self.model_path}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            raise

    def load(self):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.
        """
        if not self.model_path.exists():
            raise FileNotFoundError(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {self.model_path}")
        try:
            data = joblib.load(self.model_path)
            self.model = data["model"]
            self.preprocessor = data["preprocessor"]
            self.is_fitted = data["is_fitted"]
            logger.info(f"ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {self.model_path}")
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            raise
