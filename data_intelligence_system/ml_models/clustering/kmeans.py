import logging
import joblib
from pathlib import Path
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

from data_intelligence_system.utils.preprocessing import fill_missing_values, scale_numericals
from data_intelligence_system.ml_models.base_model import BaseModel
from data_intelligence_system.utils.timer import Timer

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class KMeansClusteringModel(BaseModel):
    def __init__(
        self,
        n_clusters: int = 3,
        init: str = 'k-means++',
        max_iter: int = 300,
        random_state: int = 42,
        scaler_type: str = "standard",
        **kwargs
    ):
        """
        Ù†Ù…ÙˆØ°Ø¬ KMeans Ù„Ù„ØªØ¬Ù…ÙŠØ¹ ØºÙŠØ± Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù.

        Parameters
        ----------
        n_clusters : int
            Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª.
        init : str
            Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©.
        max_iter : int
            Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ Ù„Ù„ØªÙƒØ±Ø§Ø±Ø§Øª.
        random_state : int
            Ø§Ù„Ø¨Ø°Ø±Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±.
        scaler_type : str
            Ù†ÙˆØ¹ Ø§Ù„ØªØ­Ø¬ÙŠÙ… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù…Ø«Ù„Ø§Ù‹ "standard").
        kwargs : dict
            Ù…Ø¹Ù„Ù…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù†Ù…ÙˆØ°Ø¬ KMeans.
        """
        super().__init__(model_name="kmeans_clustering", model_dir="data_intelligence_system/ml_models/saved_models")
        self.model = KMeans(
            n_clusters=n_clusters,
            init=init,
            max_iter=max_iter,
            random_state=random_state,
            **kwargs
        )
        self.scaler_type = scaler_type
        self.is_fitted = False
        self.X_train_ = None

    @Timer("ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ KMeans")
    def fit(self, X):
        """
        ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙˆØ§Ù„ØªØ­Ø¬ÙŠÙ….

        Parameters
        ----------
        X : pd.DataFrame
            Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù…Ø§Øª.

        Returns
        -------
        self
        """
        if X is None or X.empty:
            raise ValueError("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙØ§Ø±ØºØ© Ø£Ùˆ None.")
        X = fill_missing_values(X)
        # Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù‡Ù†Ø§: Ø§Ø³ØªØ®Ø¯Ù… scaler ÙˆÙ„ÙŠØ³ method
        X_scaled = scale_numericals(X, scaler=self.scaler_type)
        self.model.fit(X_scaled)
        self.X_train_ = X_scaled
        self.is_fitted = True
        logger.info("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ KMeans.")
        return self

    def predict(self, X):
        """
        ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.

        Parameters
        ----------
        X : pd.DataFrame
            Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³Ù…Ø§Øª.

        Returns
        -------
        np.ndarray
            ØªØ³Ù…ÙŠØ§Øª Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©.
        """
        self._check_is_fitted()
        if X is None or X.empty:
            raise ValueError("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙØ§Ø±ØºØ© Ø£Ùˆ None.")
        X = fill_missing_values(X)
        X_scaled = scale_numericals(X, scaler=self.scaler_type)
        return self.model.predict(X_scaled)

    def get_cluster_centers(self):
        """
        Ø¹Ø±Ø¶ Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª.

        Returns
        -------
        np.ndarray
            Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª.
        """
        self._check_is_fitted()
        return self.model.cluster_centers_

    def evaluate(self, X=None):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø¤Ø´Ø± Silhouette Score.

        Parameters
        ----------
        X : pd.DataFrame, optional
            Ø¨ÙŠØ§Ù†Ø§Øª Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¹Ù„ÙŠÙ‡Ø§ØŒ Ø¥Ø°Ø§ Ù„Ù… ØªÙ‚Ø¯Ù… ØªØ³ØªØ®Ø¯Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

        Returns
        -------
        float
            Ù‚ÙŠÙ…Ø© Silhouette Score.
        """
        self._check_is_fitted()
        if X is None:
            if self.X_train_ is None:
                raise ValueError("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªÙ‚ÙŠÙŠÙ….")
            X_eval = self.X_train_
        else:
            if X.empty:
                raise ValueError("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙØ§Ø±ØºØ©.")
            X_eval = fill_missing_values(X)
            X_eval = scale_numericals(X_eval, scaler=self.scaler_type)
        labels = self.model.predict(X_eval)
        score = silhouette_score(X_eval, labels)
        logger.info(f"ğŸ“ˆ Silhouette Score: {score:.4f}")
        return score

    def save(self):
        """
        Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯.
        """
        if self.model is None:
            raise ValueError("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ø­ÙØ¸Ù‡.")
        self.model_path.parent.mkdir(parents=True, exist_ok=True)
        joblib.dump({
            "model": self.model,
            "scaler_type": self.scaler_type,
            "is_fitted": self.is_fitted,
            "X_train_": self.X_train_,
        }, self.model_path)
        logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {self.model_path}")

    def load(self):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø­Ø¯Ø¯.
        """
        if not self.model_path.exists():
            raise FileNotFoundError(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {self.model_path}")
        data = joblib.load(self.model_path)
        self.model = data["model"]
        self.scaler_type = data.get("scaler_type", "standard")
        self.is_fitted = data["is_fitted"]
        self.X_train_ = data.get("X_train_", None)
        logger.info(f"ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {self.model_path}")
