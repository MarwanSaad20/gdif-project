import logging
import joblib
from pathlib import Path
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score

# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…Ù† Ø¬Ø°Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
from data_intelligence_system.utils.preprocessing import fill_missing_values, scale_numericals
from data_intelligence_system.ml_models.base_model import BaseModel
from data_intelligence_system.utils.timer import Timer

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO)


class KMeansClusteringModel(BaseModel):
    def __init__(
        self,
        n_clusters=3,
        init='k-means++',
        max_iter=300,
        random_state=None,
        scaler_type="standard",
        **kwargs
    ):
        """
        Ù†Ù…ÙˆØ°Ø¬ KMeans Ù„Ù„ØªØ¬Ù…ÙŠØ¹ ØºÙŠØ± Ø§Ù„Ø®Ø§Ø¶Ø¹ Ù„Ù„Ø¥Ø´Ø±Ø§Ù.
        """
        super().__init__(model_name="kmeans_clustering", model_dir="data_intelligence_system/ml_models/saved_models")
        self.model = KMeans(
            n_clusters=n_clusters,
            init=init,
            max_iter=max_iter,
            random_state=random_state,
            **kwargs
        )
        self.scaler_type = scaler_type
        self.is_fitted = False

    @Timer("ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ KMeans")
    def fit(self, X):
        """
        ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø¬ÙŠÙ….
        """
        X = fill_missing_values(X)
        X_scaled = scale_numericals(X, method=self.scaler_type)
        self.model.fit(X_scaled)
        self.X_train_ = X_scaled
        self.is_fitted = True
        logger.info("âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ KMeans.")
        return self

    def predict(self, X):
        """
        ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª.
        """
        self._check_is_fitted()
        X = fill_missing_values(X)
        X_scaled = scale_numericals(X, method=self.scaler_type)
        return self.model.predict(X_scaled)

    def get_cluster_centers(self):
        """
        Ø¹Ø±Ø¶ Ù…Ø±Ø§ÙƒØ² Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª.
        """
        self._check_is_fitted()
        return self.model.cluster_centers_

    def evaluate(self, X=None):
        """
        ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Silhouette Score.
        """
        self._check_is_fitted()
        if X is None and hasattr(self, "X_train_"):
            X = self.X_train_
        else:
            X = fill_missing_values(X)
            X = scale_numericals(X, method=self.scaler_type)
        labels = self.model.predict(X)
        score = silhouette_score(X, labels)
        logger.info(f"ğŸ“ˆ Silhouette Score: {score:.4f}")
        return score

    def save(self):
        """
        Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.
        """
        if self.model is None:
            raise ValueError("âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ù…ÙˆØ°Ø¬ Ù„Ø­ÙØ¸Ù‡.")
        self.model_path.parent.mkdir(parents=True, exist_ok=True)
        joblib.dump({
            "model": self.model,
            "scaler_type": self.scaler_type,
            "is_fitted": self.is_fitted
        }, self.model_path)
        logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {self.model_path}")

    def load(self):
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.
        """
        if not self.model_path.exists():
            raise FileNotFoundError(f"âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {self.model_path}")
        data = joblib.load(self.model_path)
        self.model = data["model"]
        self.scaler_type = data.get("scaler_type", "standard")
        self.is_fitted = data["is_fitted"]
        logger.info(f"ğŸ“¥ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {self.model_path}")
