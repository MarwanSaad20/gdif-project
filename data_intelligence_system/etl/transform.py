import logging
from typing import List, Tuple, Union

import numpy as np
import pandas as pd
from sklearn.preprocessing import LabelEncoder

from data_intelligence_system.data.processed.fill_missing import fill_missing
from data_intelligence_system.data.processed.scale_numericals import scale_numericals
from data_intelligence_system.etl.etl_utils import log_step  # âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù„ÙŠÙƒÙˆÙ† Ù…Ù† Ø¬Ø°Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹

logger = logging.getLogger(__name__)


def unify_column_names(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        logger.warning("âš ï¸ DataFrame ÙØ§Ø±Øº Ø£Ùˆ None ÙÙŠ unify_column_names.")
        return df

    df = df.copy()
    df.columns = (
        df.columns.str.strip()
                  .str.lower()
                  .str.replace(r'[^\w]+', '_', regex=True)
                  .str.strip('_')
    )
    logger.info(f"âœ… ØªÙˆØ­ÙŠØ¯ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {df.columns.tolist()}")
    return df


def encode_categorical_columns(df: pd.DataFrame, encode_type: str = 'label') -> pd.DataFrame:
    if df is None or df.empty:
        logger.warning("âš ï¸ DataFrame ÙØ§Ø±Øº Ø£Ùˆ None ÙÙŠ encode_categorical_columns.")
        return df

    df = df.copy()
    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    logger.info(f"ğŸ” Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ¦ÙˆÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„ØªØ±Ù…ÙŠØ²: {cat_cols}")

    for col in cat_cols:
        df[col] = df[col].apply(lambda x: str(x) if isinstance(x, (list, dict)) else x)

    if encode_type == 'label':
        for col in cat_cols:
            try:
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col].astype(str))
                logger.info(f"âœ… ØªÙ… ØªØ±Ù…ÙŠØ² {col} Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… LabelEncoder")
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ±Ù…ÙŠØ² {col}: {e}")

    elif encode_type == 'onehot':
        one_hot_cols = []
        skipped_cols = []

        for col in cat_cols:
            unique_vals = df[col].nunique()
            if unique_vals <= 1000:
                one_hot_cols.append(col)
            else:
                skipped_cols.append((col, unique_vals))
                logger.warning(f"â›” ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø¹Ù…ÙˆØ¯ '{col}' Ù„Ø§Ø­ØªÙˆØ§Ø¦Ù‡ Ø¹Ù„Ù‰ {unique_vals} Ù‚ÙŠÙ…Ø© ÙØ±ÙŠØ¯Ø© (ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ 1000)")

        try:
            if one_hot_cols:
                df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)
                logger.info(f"âœ… ØªÙ… ØªØ·Ø¨ÙŠÙ‚ One-Hot Encoding Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {one_hot_cols}")
            else:
                logger.info("â„¹ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø¤Ù‡Ù„Ø© Ù„ØªØ·Ø¨ÙŠÙ‚ One-Hot Encoding.")
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚ One-Hot Encoding: {e}")
            raise
    else:
        logger.warning(f"âš ï¸ Ù†ÙˆØ¹ Ø§Ù„ØªØ±Ù…ÙŠØ² ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ: {encode_type}")

    return df


def remove_duplicates(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        logger.warning("âš ï¸ DataFrame ÙØ§Ø±Øº Ø£Ùˆ None ÙÙŠ remove_duplicates.")
        return df

    df = df.copy()
    before = len(df)
    df = df.drop_duplicates()
    after = len(df)
    logger.info(f"âœ… Ø­Ø°Ù Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª: {before - after} ØµÙÙˆÙ Ù…ÙƒØ±Ø±Ø©")
    return df


@log_step
def transform_datasets(
    datasets: List[Tuple[str, pd.DataFrame]],
    encode_type: str = 'label',
    scale_type: str = 'standard',
) -> List[Tuple[str, pd.DataFrame]]:
    transformed = []

    if not datasets:
        logger.warning("âš ï¸ Ù‚Ø§Ø¦Ù…Ø© datasets ÙØ§Ø±ØºØ© Ø£Ùˆ None ÙÙŠ transform_datasets.")
        return transformed

    for name, df in datasets:
        if df is None or df.empty:
            logger.warning(f"âš ï¸ DataFrame ÙØ§Ø±Øº Ø£Ùˆ None ÙÙŠ transform_datasets Ù„Ù„Ù…Ù„Ù {name}.")
            continue

        logger.info(f"ğŸš§ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­ÙˆÙŠÙ„: {name}")
        logger.info(f"ğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ØµÙ„ÙŠØ©: {df.shape}")

        df = unify_column_names(df)
        df = fill_missing(df)
        df = encode_categorical_columns(df, encode_type=encode_type)
        df = scale_numericals(df)
        df = remove_duplicates(df)

        logger.info(f"âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† ØªØ­ÙˆÙŠÙ„: {name} | Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {df.shape}")
        transformed.append((name, df))

    return transformed


@log_step
def clean_data(df: pd.DataFrame) -> pd.DataFrame:
    return transform_datasets([("clean_data", df)], encode_type='label')[0][1]
