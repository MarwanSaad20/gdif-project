import os
from dataclasses import dataclass, field
from typing import Optional, Dict, Any

import pandas as pd

from data_intelligence_system.utils.logger import get_logger
from data_intelligence_system.utils.data_loader import load_data
from data_intelligence_system.analysis.descriptive_stats import generate_descriptive_stats
from data_intelligence_system.analysis.correlation_analysis import run_correlation_analysis
from data_intelligence_system.analysis.outlier_detection import run_outlier_detection
from data_intelligence_system.analysis.clustering_analysis import run_clustering
from data_intelligence_system.analysis.target_relation_analysis import run_target_relation_analysis

# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù† config
from data_intelligence_system.config.paths_config import CLEAN_DATA_FILE
logger = get_logger("analysis.service")


def run_descriptive_stats(df: pd.DataFrame) -> Dict[str, Any]:
    """
    ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªÙˆØ±Ø¯Ø©
    """
    return generate_descriptive_stats(df)


@dataclass
class AnalysisService:
    data_path: str
    data: Optional[pd.DataFrame] = field(default=None, init=False)

    def __post_init__(self):
        self.load_data()

    def load_data(self, force_reload: bool = False) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù†Ø¸ÙØ© Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø±.
        :param force_reload: ÙØ±Ø¶ Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­ØªÙ‰ Ù„Ùˆ ÙƒØ§Ù†Øª Ù…Ø­Ù…Ù„Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§.
        :return: DataFrame Ø§Ù„Ù…Ø­Ù…Ù„
        """
        if self.data is None or force_reload:
            if not os.path.exists(self.data_path):
                logger.error(f"âŒ Ø§Ù„Ù…Ø³Ø§Ø± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {self.data_path}")
                raise FileNotFoundError(f"File not found: {self.data_path}")

            try:
                logger.info(f"ğŸ“ Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù: {self.data_path}")
                self.data = load_data(self.data_path)
                logger.info(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­ Ù…Ù†: {self.data_path}")
            except Exception as e:
                logger.exception(f"âŒ ÙØ´Ù„ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† {self.data_path}: {e}")
                raise
        return self.data

    def descriptive_statistics(self) -> Dict[str, Any]:
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØµÙÙŠ...")
        df = self.load_data()
        return run_descriptive_stats(df)

    def correlation_analysis(self, method: str = "pearson") -> Dict[str, Any]:
        logger.info(f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {method}")
        df = self.load_data()
        return run_correlation_analysis(df, method=method)

    def outlier_detection(self, method: str = "iqr") -> Dict[str, Any]:
        logger.info(f"âš ï¸ ÙƒØ´Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø´Ø§Ø°Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {method}")
        df = self.load_data()
        return run_outlier_detection(df, method=method)

    def clustering_insights(self, algorithm: str = "kmeans", n_clusters: int = 3) -> Dict[str, Any]:
        logger.info(f"ğŸ“Š Ø§Ù„ØªØ¬Ù…ÙŠØ¹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {algorithm} Ø¨Ø¹Ø¯Ø¯ {n_clusters} Ù…Ø¬Ù…ÙˆØ¹Ø§Øª")
        df = self.load_data()
        return run_clustering(df, algorithm=algorithm, n_clusters=n_clusters)

    def target_relationship(self, target_column: Optional[str] = None) -> Dict[str, Any]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ù…Ø¹ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù Ø§Ù„Ù…Ø­Ø¯Ø¯ØŒ ÙˆØ¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ø¯ÙŠØ¯Ù‡ØŒ ÙŠÙØ³ØªØ®Ø¯Ù… Ø¢Ø®Ø± Ø¹Ù…ÙˆØ¯.
        Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ø§Ù„Ø¹Ù…ÙˆØ¯ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ØŒ ÙŠØªÙ… Ø§Ù„ØªØ­Ø°ÙŠØ± ÙˆÙŠØªÙ… ØªØ¬Ø§ÙˆØ² Ø§Ù„ØªØ­Ù„ÙŠÙ„.
        """
        df = self.load_data()
        target = target_column if target_column else df.columns[-1]

        if target not in df.columns:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù‡Ø¯Ù: {target}")
            return {"warning": f"Target column '{target}' not found in data."}

        logger.info(f"ğŸ¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ù…Ø¹ Ø§Ù„Ù‡Ø¯Ù: {target}")
        return run_target_relation_analysis(df, target_col=target)


if __name__ == "__main__":
    from data_intelligence_system.utils.logger import get_logger
    logger = get_logger("analysis.cli", reset=True)

    # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… CLEAN_DATA_PATH Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ø³Ø§Ø± Ù…Ø¨Ø§Ø´Ø±Ø©Ù‹
    data_file_path = str(CLEAN_DATA_PATH)

    if not os.path.exists(data_file_path):
        logger.error(f"Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {data_file_path}")
        exit(1)

    service = AnalysisService(data_path=data_file_path)

    print("\n[1] Descriptive Statistics:")
    print(service.descriptive_statistics())

    print("\n[2] Correlation Analysis:")
    print(service.correlation_analysis())

    print("\n[3] Outlier Detection:")
    print(service.outlier_detection())

    print("\n[4] Clustering Insights:")
    print(service.clustering_insights())

    print("\n[5] Target Relationship Analysis:")
    print(service.target_relationship(target_column="species"))
