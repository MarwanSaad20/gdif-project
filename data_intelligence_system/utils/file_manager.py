import os
import pandas as pd
import json
from datetime import datetime
import shutil
import base64
import uuid
from pathlib import Path

# âœ… Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù„ÙˆØ¬Ø± Ø§Ù„Ù…ÙˆØ­Ù‘Ø¯
from data_intelligence_system.utils.logger import get_logger

logger = get_logger(name="FileManager")


# ====================
# ğŸ“¥ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ====================
def read_file(filepath: str, encoding: str = "utf-8") -> pd.DataFrame:
    ext = os.path.splitext(filepath)[1].lower()

    try:
        if ext == ".csv":
            return pd.read_csv(filepath, encoding=encoding)

        elif ext in [".xls", ".xlsx"]:
            return pd.read_excel(filepath)

        elif ext == ".json":
            with open(filepath, "r", encoding=encoding) as f:
                data = json.load(f)

            if isinstance(data, dict):
                return pd.json_normalize(data)

            elif isinstance(data, list):
                if all(isinstance(item, dict) for item in data):
                    return pd.json_normalize(data)
                elif all(isinstance(item, list) for item in data):
                    return pd.DataFrame(data)
                elif all(isinstance(item, (list, dict)) for item in data):
                    return pd.DataFrame(data)
                else:
                    raise RuntimeError(
                        f"âš ï¸ JSON contains unsupported list elements â†’ type: {type(data[0])} in: {filepath}"
                    )

            else:
                raise RuntimeError(f"âš ï¸ Unsupported JSON root type: {type(data)} in: {filepath}")

        elif ext == ".parquet":
            return pd.read_parquet(filepath)

        elif ext == ".tsv":
            return pd.read_csv(filepath, sep="\t", encoding=encoding)

        elif ext == ".feather":
            return pd.read_feather(filepath)

        else:
            raise ValueError(f"âŒ Unsupported file format: {ext}")

    except Exception as e:
        logger.exception(f"âš ï¸ Failed to read file '{filepath}': {e}")
        raise RuntimeError(f"âš ï¸ Failed to read file '{filepath}': {e}")


# ====================
# ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ====================
def save_file(df: pd.DataFrame, filepath: str, encoding: str = "utf-8", compress: bool = False):
    ext = os.path.splitext(filepath)[1].lower()
    os.makedirs(os.path.dirname(filepath), exist_ok=True)

    try:
        if ext == ".csv":
            df.to_csv(filepath, index=False, encoding=encoding, compression="gzip" if compress else None)
        elif ext in [".xls", ".xlsx"]:
            df.to_excel(filepath, index=False)
        elif ext == ".json":
            df.to_json(filepath, orient="records", indent=4, force_ascii=False)
        elif ext == ".parquet":
            df.to_parquet(filepath, index=False, compression="snappy" if compress else None)
        elif ext == ".feather":
            df.to_feather(filepath)
        else:
            raise ValueError(f"âŒ Unsupported file format: {ext}")
    except Exception as e:
        logger.exception(f"âš ï¸ Failed to save file '{filepath}': {e}")
        raise RuntimeError(f"âš ï¸ Failed to save file '{filepath}': {e}")


# ====================
# ğŸ” ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠÙ† Ø§Ù„ØµÙŠØº
# ====================
def convert_file_format(source_path: str, target_format: str, target_path: str = None, encoding: str = "utf-8"):
    supported_formats = [".csv", ".xlsx", ".json", ".parquet", ".feather"]

    if not target_format.startswith("."):
        target_format = "." + target_format.lower()

    if target_format not in supported_formats:
        raise ValueError(f"âŒ Unsupported target format: {target_format}")

    df = read_file(source_path, encoding=encoding)

    if not target_path:
        base, _ = os.path.splitext(source_path)
        target_path = f"{base}{target_format}"

    save_file(df, target_path, encoding=encoding)
    return target_path


# ====================
# ğŸ”  Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù ÙÙ‚Ø· Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯
# ====================
def extract_file_name(filepath: str) -> str:
    base = os.path.basename(filepath)
    name = os.path.splitext(base)[0]
    return name


# ====================
# ğŸ“¤ Ø­ÙØ¸ Ù…Ù„Ù Ù…Ø±ÙÙˆØ¹ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ø¨Ø± ÙˆØ§Ø¬Ù‡Ø© Dash
# ====================
def save_uploaded_file(content: str, filename: str, target_dir: str = "data/raw") -> str:
    try:
        content_type, content_string = content.split(',')
        decoded = base64.b64decode(content_string)

        ext = os.path.splitext(filename)[1]
        unique_id = uuid.uuid4().hex[:8]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_name = f"{timestamp}_{unique_id}{ext}"

        os.makedirs(target_dir, exist_ok=True)
        path = os.path.join(target_dir, safe_name)

        with open(path, "wb") as f:
            f.write(decoded)

        return path

    except Exception as e:
        logger.exception(f"âŒ Failed to save uploaded file: {e}")
        raise RuntimeError(f"âŒ Failed to save uploaded file: {e}")


# ====================
# ğŸ•‘ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ù…Ù„Ù Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ù…Ø¬Ù„Ø¯ data/processed
# ====================
def get_latest_processed_file(directory: str = "data/processed") -> str | None:
    """
    ÙŠØ¹ÙŠØ¯ Ù…Ø³Ø§Ø± Ø£Ø­Ø¯Ø« Ù…Ù„Ù .csv ØªÙ… Ø­ÙØ¸Ù‡ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.
    """
    try:
        csv_files = list(Path(directory).glob("*.csv"))
        if not csv_files:
            return None
        latest_file = max(csv_files, key=lambda x: x.stat().st_mtime)
        return str(latest_file)
    except Exception as e:
        logger.exception(f"âŒ Failed to find latest processed file: {e}")
        raise RuntimeError(f"âŒ Failed to find latest processed file: {e}")
