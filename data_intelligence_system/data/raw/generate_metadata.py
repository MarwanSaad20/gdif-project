import os
import pandas as pd
import json
from datetime import datetime
import logging

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))

# 🔧 المسار الجذري والمجلدات
RAW_DIR = os.path.join(BASE_DIR, 'data', 'raw')  # مسار ملفات البيانات الخام
LOG_DIR = os.path.join(BASE_DIR, 'logs')         # مجلد السجلات
os.makedirs(LOG_DIR, exist_ok=True)

ENCODING = "utf-8"
SUPPORTED_EXTENSIONS = ['.csv', '.json', '.xlsx']

# 📝 إعداد اللوج
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("GenerateMetadata")


def infer_file_metadata(filepath):
    filename = os.path.basename(filepath)
    ext = os.path.splitext(filepath)[1].lower()

    try:
        if ext == '.csv':
            df = pd.read_csv(filepath, encoding=ENCODING)
        elif ext == '.json':
            try:
                df = pd.read_json(filepath, lines=True)
            except ValueError:
                with open(filepath, encoding=ENCODING) as f:
                    data = json.load(f)
                    df = pd.json_normalize(data)
        elif ext == '.xlsx':
            df = pd.read_excel(filepath)
        else:
            logger.warning(f"⚠️ ملف غير مدعوم للمعالجة: {filename}")
            return None

        metadata = {
            "filename": filename,
            "format": ext.replace(".", "").upper(),
            "columns": df.columns.tolist(),
            "column_types": df.dtypes.astype(str).to_dict(),
            "column_count": df.shape[1],
            "row_count": df.shape[0],
            "num_missing_values": int(df.isnull().sum().sum()),
            "sample_preview": df.head(2).to_dict(orient="records"),
            "source": "Unknown",
            "acquisition_date": datetime.now().strftime("%Y-%m-%d"),
            "encoding": ENCODING,
            "description": "Autogenerated metadata",
            "verified": False
        }
        return metadata
    except Exception as e:
        logger.error(f"❌ خطأ أثناء معالجة الملف {filename}: {e}")
        return None


def save_metadata(filepath, metadata):
    json_path = filepath.replace(os.path.splitext(filepath)[1], ".metadata.json")
    try:
        with open(json_path, "w", encoding=ENCODING) as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)
        logger.info(f"✅ تم حفظ بيانات التعريف: {os.path.basename(json_path)}")
    except Exception as e:
        logger.error(f"❌ فشل حفظ بيانات التعريف للملف {os.path.basename(filepath)}: {e}")


def main():
    logger.info("📄 بدء توليد بيانات التعريف للملفات الخام...\n")

    if not os.path.exists(RAW_DIR):
        logger.error(f"❌ مجلد البيانات الخام غير موجود: {RAW_DIR}")
        return

    for root, _, files in os.walk(RAW_DIR):
        for file in files:
            full_path = os.path.join(root, file)
            ext = os.path.splitext(file)[1].lower()

            if ext not in SUPPORTED_EXTENSIONS or not os.path.isfile(full_path):
                continue

            metadata_path = full_path.replace(ext, ".metadata.json")
            if os.path.exists(metadata_path):
                logger.info(f"🟡 بيانات التعريف موجودة مسبقاً: {file}. ⏭️ تخطي...")
                continue

            metadata = infer_file_metadata(full_path)
            if metadata:
                save_metadata(full_path, metadata)

    logger.info("\n🎯 انتهى التوليد بنجاح.")


if __name__ == "__main__":
    main()
