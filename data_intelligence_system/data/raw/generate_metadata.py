import os
import pandas as pd
import json
from datetime import datetime
import logging

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))

# ğŸ”§ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ø¬Ø°Ø±ÙŠ ÙˆØ§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
RAW_DIR = os.path.join(BASE_DIR, 'data', 'raw')  # Ù…Ø³Ø§Ø± Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…
LOG_DIR = os.path.join(BASE_DIR, 'logs')         # Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
os.makedirs(LOG_DIR, exist_ok=True)

ENCODING = "utf-8"
SUPPORTED_EXTENSIONS = ['.csv', '.json', '.xlsx']

# ğŸ“ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆØ¬
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("GenerateMetadata")


def infer_file_metadata(filepath):
    filename = os.path.basename(filepath)
    ext = os.path.splitext(filepath)[1].lower()

    try:
        if ext == '.csv':
            df = pd.read_csv(filepath, encoding=ENCODING)
        elif ext == '.json':
            try:
                df = pd.read_json(filepath, lines=True)
            except ValueError:
                with open(filepath, encoding=ENCODING) as f:
                    data = json.load(f)
                    df = pd.json_normalize(data)
        elif ext == '.xlsx':
            df = pd.read_excel(filepath)
        else:
            logger.warning(f"âš ï¸ Ù…Ù„Ù ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {filename}")
            return None

        metadata = {
            "filename": filename,
            "format": ext.replace(".", "").upper(),
            "columns": df.columns.tolist(),
            "column_types": df.dtypes.astype(str).to_dict(),
            "column_count": df.shape[1],
            "row_count": df.shape[0],
            "num_missing_values": int(df.isnull().sum().sum()),
            "sample_preview": df.head(2).to_dict(orient="records"),
            "source": "Unknown",
            "acquisition_date": datetime.now().strftime("%Y-%m-%d"),
            "encoding": ENCODING,
            "description": "Autogenerated metadata",
            "verified": False
        }
        return metadata
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù {filename}: {e}")
        return None


def save_metadata(filepath, metadata):
    json_path = filepath.replace(os.path.splitext(filepath)[1], ".metadata.json")
    try:
        with open(json_path, "w", encoding=ENCODING) as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)
        logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙ: {os.path.basename(json_path)}")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙ Ù„Ù„Ù…Ù„Ù {os.path.basename(filepath)}: {e}")


def main():
    logger.info("ğŸ“„ Ø¨Ø¯Ø¡ ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø®Ø§Ù…...\n")

    if not os.path.exists(RAW_DIR):
        logger.error(f"âŒ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù… ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {RAW_DIR}")
        return

    for root, _, files in os.walk(RAW_DIR):
        for file in files:
            full_path = os.path.join(root, file)
            ext = os.path.splitext(file)[1].lower()

            if ext not in SUPPORTED_EXTENSIONS or not os.path.isfile(full_path):
                continue

            metadata_path = full_path.replace(ext, ".metadata.json")
            if os.path.exists(metadata_path):
                logger.info(f"ğŸŸ¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙ Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹: {file}. â­ï¸ ØªØ®Ø·ÙŠ...")
                continue

            metadata = infer_file_metadata(full_path)
            if metadata:
                save_metadata(full_path, metadata)

    logger.info("\nğŸ¯ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù†Ø¬Ø§Ø­.")


if __name__ == "__main__":
    main()
