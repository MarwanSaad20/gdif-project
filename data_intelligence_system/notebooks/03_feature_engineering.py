# =============================
# âš™ï¸ 03 â€“ Feature Engineering
# =============================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import PolynomialFeatures
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from pathlib import Path
import sys
import warnings

warnings.filterwarnings("ignore")
sns.set_theme(style="whitegrid")

# ============================
# ğŸ“‚ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# ============================

def load_data():
    try:
        # Ù†ØµØ¹Ø¯ Ù…Ø±ØªÙŠÙ† Ù„Ù„ÙˆØµÙˆÙ„ Ù„Ø¬Ø°Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ PythonProject10
        project_root = Path(__file__).resolve().parents[2]
    except NameError:
        project_root = Path.cwd().parents[1]

    # âœ… Ø¥Ø¶Ø§ÙØ© Ø¬Ø°Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¥Ù„Ù‰ sys.path Ù„Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ config/paths_config.py
    if str(project_root) not in sys.path:
        sys.path.insert(0, str(project_root))

    data_path = project_root / "data_intelligence_system" / "data" / "processed" / "clean_data.csv"
    if not data_path.exists():
        raise FileNotFoundError(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {data_path}")
    df = pd.read_csv(data_path)
    print(f"âœ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©: {df.shape}")
    return df

# =============================================
# ğŸ§ª ØªÙˆÙ„ÙŠØ¯ Ø³Ù…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø´ØªÙ‚Ø© (ÙØ±Ù‚ØŒ Ù†Ø³Ø¨ØŒ Ù…Ø¬Ù…ÙˆØ¹)
# =============================================

def generate_derived_features(df):
    numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()
    if len(numeric_cols) >= 2:
        df['diff_feature'] = df[numeric_cols[0]] - df[numeric_cols[1]]
        df['ratio_feature'] = df[numeric_cols[0]] / (df[numeric_cols[1]] + 1e-5)
        df['sum_feature'] = df[numeric_cols[0]] + df[numeric_cols[1]]
        print("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù…Ø´ØªÙ‚Ø© (ÙØ±Ù‚ØŒ Ù†Ø³Ø¨Ø©ØŒ Ù…Ø¬Ù…ÙˆØ¹)")
    return df, numeric_cols

# ===========================================
# ğŸ§® Polynomial Features (ØªÙØ§Ø¹Ù„Ø§Øª Ù…Ø±ØªØ¨Ø©)
# ===========================================

def generate_polynomial_features(df, numeric_cols):
    if len(numeric_cols) >= 2:
        poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)
        poly_features = poly.fit_transform(df[[numeric_cols[0], numeric_cols[1]]])
        poly_df = pd.DataFrame(poly_features, columns=poly.get_feature_names_out([numeric_cols[0], numeric_cols[1]]))
        df = pd.concat([df, poly_df.iloc[:, 2:]], axis=1)  # Ø§Ø³ØªØ«Ù†Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
        print("âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø³Ù…Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø­Ø¯ÙˆØ¯ (ØªÙØ§Ø¹Ù„ÙŠØ©)")
    return df

# =================================
# â³ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø³Ù…Ø§Øª Ù…Ù† Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®
# =================================

def generate_datetime_features(df):
    object_cols = df.select_dtypes(include=["object"]).columns.tolist()
    for col in object_cols:
        try:
            sample = df[col].dropna().iloc[0]
            pd.to_datetime(sample)  # Ù…Ø­Ø§ÙˆÙ„Ø© Ø£ÙˆÙ„ÙŠØ© Ù„Ù„ØªØ­Ù‚Ù‚
            df[col] = pd.to_datetime(df[col], errors='coerce')
            df[f"{col}_year"] = df[col].dt.year
            df[f"{col}_month"] = df[col].dt.month
            df[f"{col}_day"] = df[col].dt.day
            df[f"{col}_weekday"] = df[col].dt.weekday
            print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ù…Ø§Øª Ø²Ù…Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ø¹Ù…ÙˆØ¯: {col}")
        except Exception:
            continue
    return df

# ============================================
# â­ ØªØ­Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø³Ù…Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Random Forest
# ============================================

def feature_importance_analysis(df):
    possible_targets = [col for col in df.columns if col.lower() in ["target", "label", "y"]]
    
    if not possible_targets:
        print("ğŸš« Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ù‡Ø¯Ù. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ù„ØªØ­Ø¯ÙŠØ¯Ù‡.")
        print(f"ğŸ§  Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©: {list(df.columns)}")
        return
    
    target = possible_targets[0]
    print(f"ğŸ¯ Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¹Ù…ÙˆØ¯ '{target}' ÙƒÙ‡Ø¯Ù.")

    X = df.drop(columns=[target]).select_dtypes(include=["float64", "int64"]).fillna(0)
    y = df[target]

    if y.nunique() <= 10:
        model = RandomForestClassifier(random_state=42)
    else:
        model = RandomForestRegressor(random_state=42)

    model.fit(X, y)
    importances = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)

    plt.figure(figsize=(10, 6))
    sns.barplot(x=importances.values[:10], y=importances.index[:10], palette='viridis')
    plt.title("Top 10 Feature Importances")
    plt.tight_layout()
    plt.show()
    print("âœ… ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ø³Ù…Ø§Øª.")

# ======================
# ğŸš€ Ù†Ù‚Ø·Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±Ø¨Øª
# ======================

if __name__ == "__main__":
    df = load_data()
    df, numeric_cols = generate_derived_features(df)
    df = generate_polynomial_features(df, numeric_cols)
    df = generate_datetime_features(df)
    feature_importance_analysis(df)
